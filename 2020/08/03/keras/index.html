<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Keras | 月落晓山的博客</title><meta name="keywords" content="机器学习,Keras"><meta name="author" content="月落"><meta name="copyright" content="月落"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Keras中文文档笔记，从零开始摸爬滚打~">
<meta property="og:type" content="article">
<meta property="og:title" content="Keras">
<meta property="og:url" content="https://wanfengyueluo.github.io/2020/08/03/keras/index.html">
<meta property="og:site_name" content="月落晓山的博客">
<meta property="og:description" content="Keras中文文档笔记，从零开始摸爬滚打~">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://wanfengyueluo.github.io/images/cover1.jpg">
<meta property="article:published_time" content="2020-08-03T13:20:55.000Z">
<meta property="article:modified_time" content="2021-06-03T13:31:51.760Z">
<meta property="article:author" content="月落">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="Keras">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://wanfengyueluo.github.io/images/cover1.jpg"><link rel="shortcut icon" href="/images/favicon.png"><link rel="canonical" href="https://wanfengyueluo.github.io/2020/08/03/keras/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Keras',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-06-03 21:31:51'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.1"><link rel="alternate" href="/atom.xml" title="月落晓山的博客" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/images/avataaars.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">63</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">43</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/images/cover1.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">月落晓山的博客</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Keras</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-08-03T13:20:55.000Z" title="发表于 2020-08-03 21:20:55">2020-08-03</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-06-03T13:31:51.760Z" title="更新于 2021-06-03 21:31:51">2021-06-03</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>20分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Keras"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote>
<p>“我要忘了你的样子，像鱼忘了海的味道——像鱼”</p>
</blockquote>
<h2 id="1-Keras-Sequentical顺序模型"><a href="#1-Keras-Sequentical顺序模型" class="headerlink" title="1. Keras Sequentical顺序模型"></a>1. Keras Sequentical顺序模型</h2><p>顺序模型是多个网络层的线性堆叠，可以通过将网络层实例的列表传递给<code>Sequential</code>的构造器，创建一个<code>Sequential</code>模型：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense,Activation</span><br><span class="line"></span><br><span class="line">model = Sequential([</span><br><span class="line">    Dense(<span class="number">32</span>, input_shape=(<span class="number">784</span>,)),</span><br><span class="line">    Activition(<span class="string">'relu'</span>),</span><br><span class="line">    Dense(<span class="number">10</span>),</span><br><span class="line">    Activition(<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br></pre></td></tr></tbody></table></figure>
<p>或者使用<code>.add()</code>方法将各层添加到模型中</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">32</span>, input_dim=<span class="number">784</span>))</span><br><span class="line">model.add(Activition(<span class="string">'relu'</span>))</span><br></pre></td></tr></tbody></table></figure>
<h3 id="指定输入数据的尺寸"><a href="#指定输入数据的尺寸" class="headerlink" title="指定输入数据的尺寸"></a>指定输入数据的尺寸</h3><p>模型需要知道它所期望的输入尺寸，所以顺序模型的第一层需要接收关于输入尺寸的信息，其余层可以自动推断尺寸。方法如下：</p>
<ul>
<li>传递一个<code>input_shape</code>参数，它是一个表示尺寸的元组 (一个由整数或 <code>None</code> 组成的元组，其中 <code>None</code> 表示可能为任何正整数)。在 <code>input_shape</code> 中不包含数据的 batch 大小。</li>
<li>某些2D层，如<code>Dense</code>，支持通过参数<code>input_dim</code>指定输入尺寸；某些3D时序层支持<code>input_dim</code>和<code>input_length</code>参数。</li>
<li>如果你需要为你的输入指定一个固定的 batch 大小（这对 stateful RNNs 很有用），你可以传递一个 <code>batch_size</code> 参数给一个层。如果你同时将 <code>batch_size=32</code> 和 <code>input_shape=(6, 8)</code> 传递给一个层，那么每一批输入的尺寸就为 <code>(32，6，8)</code>。</li>
</ul>
<p>以下代码是等价的：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">32</span>, input_shape=(<span class="number">784</span>,)))</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">32</span>, input_dim=<span class="number">784</span>))</span><br></pre></td></tr></tbody></table></figure>
<h3 id="模型编译"><a href="#模型编译" class="headerlink" title="模型编译"></a>模型编译</h3><p>在训练模型之前，需要配置学习过程，通过<code>compile</code>方法完成。它接收三个参数：</p>
<ul>
<li>优化器optimizer。</li>
<li>损失函数loss，模型试图最小化的目标函数。</li>
<li>评估标准metrics。</li>
</ul>
<p>一些例子：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多分类问题</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">'rmsprop'</span>,loss=<span class="string">'categorical_crossentropy'</span>,metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 二分类问题</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">'rmsprop'</span>,loss=<span class="string">'binary_crossentropy'</span>,metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 均方误差回归问题</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">'rmsprop'</span>,loss=<span class="string">'mse'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义评估标准函数</span></span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> K</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mean_pred</span>(<span class="params">y_true, y_pred</span>):</span></span><br><span class="line">    <span class="keyword">return</span> K.mean(y_pred)</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">              loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>, mean_pred])</span><br></pre></td></tr></tbody></table></figure>
<h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><p>Keras模型在输入数据和标签的Numpy矩阵上进行训练，使用<code>fit</code>函数：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于二分类</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">32</span>, activation=<span class="string">'relu'</span>,input_dim=<span class="number">100</span>))</span><br><span class="line">mdoel.add(Dense(<span class="number">1</span>,activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">'rmsprop'</span>,loss=<span class="string">'binary_crossentropy'</span>,metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成虚拟数据</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data = np.random.random((<span class="number">1000</span>, <span class="number">100</span>))</span><br><span class="line">labels = np.random.randint(<span class="number">2</span>, size=(<span class="number">1000</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型，以 32 个样本为一个 batch 进行迭代</span></span><br><span class="line">model.fit(data, labels, epochs=<span class="number">10</span>, batch_size=<span class="number">32</span>)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于多分类</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">32</span>, activation=<span class="string">'relu'</span>,input_dim=<span class="number">100</span>))</span><br><span class="line">mdoel.add(Dense(<span class="number">10</span>,activation=<span class="string">'softmax'</span>))</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">'rmsprop'</span>,loss=<span class="string">'categorical_crossentropy'</span>,metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成虚拟数据</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data = np.random.random((<span class="number">1000</span>, <span class="number">100</span>))</span><br><span class="line">labels = np.random.randint(<span class="number">10</span>, size=(<span class="number">1000</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将标签转换为分类的 one-hot 编码</span></span><br><span class="line">one_hot_labels = keras.utils.to_categorical(labels, num_classes=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型，以 32 个样本为一个 batch 进行迭代</span></span><br><span class="line">model.fit(data, one_hot_labels, epochs=<span class="number">10</span>, batch_size=<span class="number">32</span>)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="样例"><a href="#样例" class="headerlink" title="样例"></a>样例</h3><h4 id="基于多层感知器（MLP）的softmax多分类："><a href="#基于多层感知器（MLP）的softmax多分类：" class="headerlink" title="基于多层感知器（MLP）的softmax多分类："></a>基于多层感知器（MLP）的softmax多分类：</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense,Activation,Dropout</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成虚拟数据</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x_train = np.random.random((<span class="number">1000</span>, <span class="number">20</span>))</span><br><span class="line">y_train = keras.utils.to_categorical(np.random.randint(<span class="number">10</span>, size=(<span class="number">1000</span>, <span class="number">1</span>)), num_classes=<span class="number">10</span>)</span><br><span class="line">x_test = np.random.random((<span class="number">100</span>, <span class="number">20</span>))</span><br><span class="line">y_test = keras.utils.to_categorical(np.random.randint(<span class="number">10</span>, size=(<span class="number">100</span>, <span class="number">1</span>)), num_classes=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># Dense(64) 是一个具有 64 个隐藏神经元的全连接层。</span></span><br><span class="line"><span class="comment"># 在第一层必须指定所期望的输入数据尺寸,在这里，是一个 20 维的向量。</span></span><br><span class="line">model.add(Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>, input_dim=<span class="number">20</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>))</span><br><span class="line"></span><br><span class="line">sgd = SGD(lr=<span class="number">0.01</span>, decay=<span class="number">1e-6</span>, momentum=<span class="number">0.9</span>, nesterov=<span class="literal">True</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">              optimizer=sgd,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">          epochs=<span class="number">20</span>,</span><br><span class="line">          batch_size=<span class="number">128</span>)</span><br><span class="line">score = model.evaluate(x_test, y_test, batch_size=<span class="number">128</span>)</span><br></pre></td></tr></tbody></table></figure>
<h4 id="基于多层感知器的二分类："><a href="#基于多层感知器的二分类：" class="headerlink" title="基于多层感知器的二分类："></a>基于多层感知器的二分类：</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成虚拟数据</span></span><br><span class="line">x_train = np.random.random((<span class="number">1000</span>, <span class="number">20</span>))</span><br><span class="line">y_train = np.random.randint(<span class="number">2</span>, size=(<span class="number">1000</span>, <span class="number">1</span>))</span><br><span class="line">x_test = np.random.random((<span class="number">100</span>, <span class="number">20</span>))</span><br><span class="line">y_test = np.random.randint(<span class="number">2</span>, size=(<span class="number">100</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">64</span>, input_dim=<span class="number">20</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">              optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">          epochs=<span class="number">20</span>,</span><br><span class="line">          batch_size=<span class="number">128</span>)</span><br><span class="line">score = model.evaluate(x_test, y_test, batch_size=<span class="number">128</span>)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h4 id="类似-VGG-的卷积神经网络："><a href="#类似-VGG-的卷积神经网络：" class="headerlink" title="类似 VGG 的卷积神经网络："></a>类似 VGG 的卷积神经网络：</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout, Flatten</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, MaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成虚拟数据</span></span><br><span class="line">x_train = np.random.random((<span class="number">100</span>, <span class="number">100</span>, <span class="number">100</span>, <span class="number">3</span>))</span><br><span class="line">y_train = keras.utils.to_categorical(np.random.randint(<span class="number">10</span>, size=(<span class="number">100</span>, <span class="number">1</span>)), num_classes=<span class="number">10</span>)</span><br><span class="line">x_test = np.random.random((<span class="number">20</span>, <span class="number">100</span>, <span class="number">100</span>, <span class="number">3</span>))</span><br><span class="line">y_test = keras.utils.to_categorical(np.random.randint(<span class="number">10</span>, size=(<span class="number">20</span>, <span class="number">1</span>)), num_classes=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># 输入: 3 通道 100x100 像素图像 -&gt; (100, 100, 3) 张量。</span></span><br><span class="line"><span class="comment"># 使用 32 个大小为 3x3 的卷积滤波器。</span></span><br><span class="line">model.add(Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>, input_shape=(<span class="number">100</span>, <span class="number">100</span>, <span class="number">3</span>)))</span><br><span class="line">model.add(Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(Dropout(<span class="number">0.25</span>))</span><br><span class="line"></span><br><span class="line">model.add(Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(Dropout(<span class="number">0.25</span>))</span><br><span class="line"></span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>))</span><br><span class="line"></span><br><span class="line">sgd = SGD(lr=<span class="number">0.01</span>, decay=<span class="number">1e-6</span>, momentum=<span class="number">0.9</span>, nesterov=<span class="literal">True</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">'categorical_crossentropy'</span>, optimizer=sgd)</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">10</span>)</span><br><span class="line">score = model.evaluate(x_test, y_test, batch_size=<span class="number">32</span>)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="2-Keras-函数式API"><a href="#2-Keras-函数式API" class="headerlink" title="2.     Keras 函数式API"></a>2.     Keras 函数式API</h2><h3 id="例一：全连接网络"><a href="#例一：全连接网络" class="headerlink" title="例一：全连接网络"></a>例一：全连接网络</h3><ul>
<li>网络层的实例是可调用的，它以张量为参数，并且返回一个张量</li>
<li>输入和输出均为张量，它们都可以用来定义一个模型（<code>Model</code>）</li>
<li>这样的模型同 <code>Keras</code> 的 <code>Sequential</code> 模型一样，都可以被训练</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Dense</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这部分返回一个张量</span></span><br><span class="line">inputs = Input(shape=(<span class="number">784</span>,))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 层的实例是可调用的，以张量为参数，并且返回一个张量</span></span><br><span class="line">x = Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>)(inputs)</span><br><span class="line">x = Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">predictions = Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这部分创建一个包含输入层和三个全连接层的模型</span></span><br><span class="line">model = Model(inputs=inputs, outputs=predictions)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">'rmsprop'</span>,loss=<span class="string">'categorical_crossentropy'</span>,metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.fit(data, labels) <span class="comment"># 开始训练</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="所有的模型都可调用，就像网络层一样"><a href="#所有的模型都可调用，就像网络层一样" class="headerlink" title="所有的模型都可调用，就像网络层一样"></a>所有的模型都可调用，就像网络层一样</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> TimeDistributed</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入张量是20个时间步的序列</span></span><br><span class="line"><span class="comment"># 每一个时间为一个784维的向量</span></span><br><span class="line">input_sequences = Input(shape=(<span class="number">20</span>,<span class="number">784</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这部分将我们之前定义的模型应用于输入序列中的每个时间步。</span></span><br><span class="line"><span class="comment"># 之前定义的模型的输出是一个 10-way softmax，</span></span><br><span class="line"><span class="comment"># 因而下面的层的输出将是维度为 10 的 20 个向量的序列。</span></span><br><span class="line">processed_sequences = TimeDistributed(model)(input_sequences)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="多输入多输出模型"><a href="#多输入多输出模型" class="headerlink" title="多输入多输出模型"></a>多输入多输出模型</h3><p>我们试图预测 Twitter 上的一条新闻标题有多少转发和点赞数。模型的主要输入将是新闻标题本身，即一系列词语，但是为了增添趣味，我们的模型还添加了其他的辅助输入来接收额外的数据，例如新闻标题的发布的时间等。 该模型也将通过两个损失函数进行监督学习。较早地在模型中使用主损失函数，是深度学习模型的一个良好正则方法。</p>
<p>模型结构如下图所示：</p>
<p><img src="../../../Wanfengyueluo.github.io/source/_posts/Keras/1596629447012.png" alt="1596629447012"></p>
<p>主要输入接收新闻标题本身，即一个整数序列（每个整数编码一个词）。 这些整数在 1 到 10,000 之间（10,000 个词的词汇表），且序列长度为 100 个词。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Embedding, LSTM, Dense</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标题输入：接收一个含有 100 个整数的序列，每个整数在 1 到 10000 之间。</span></span><br><span class="line"><span class="comment"># 注意我们可以通过传递一个 "name" 参数来命名任何层。</span></span><br><span class="line">main_input = Input(shape=(<span class="number">100</span>,), dtype=<span class="string">'int32'</span>, name=<span class="string">'main_input'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Embedding 层将输入序列编码为一个稠密向量的序列，</span></span><br><span class="line"><span class="comment"># 每个向量维度为 512。</span></span><br><span class="line">x = Embedding(output_dim=<span class="number">512</span>, input_dim=<span class="number">10000</span>, input_length=<span class="number">100</span>)(main_input)</span><br><span class="line"></span><br><span class="line"><span class="comment"># LSTM 层把向量序列转换成单个向量，</span></span><br><span class="line"><span class="comment"># 它包含整个序列的上下文信息</span></span><br><span class="line">lstm_out = LSTM(<span class="number">32</span>)(x)</span><br></pre></td></tr></tbody></table></figure>
<p>在这里，我们插入辅助损失，使得即使在模型主损失很高的情况下，LSTM 层和 Embedding 层都能被平稳地训练。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">auxiliary_output = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>, name=<span class="string">'aux_output'</span>)(lstm_out)</span><br></pre></td></tr></tbody></table></figure>
<p>此时，我们将辅助输入数据与 LSTM 层的输出连接起来，输入到模型中：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">auxiliary_input = Input(shape=(<span class="number">5</span>,), name=<span class="string">'aux_input'</span>)</span><br><span class="line">x = keras.layers.concatenate([lstm_out, auxiliary_input])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 堆叠多个全连接网络层</span></span><br><span class="line">x = Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">x = Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">x = Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>)(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最后添加主要的逻辑回归层</span></span><br><span class="line">main_output = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>, name=<span class="string">'main_output'</span>)(x)</span><br></pre></td></tr></tbody></table></figure>
<p>然后定义一个具有两个输入和两个输出的模型：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])</span><br></pre></td></tr></tbody></table></figure>
<p>现在编译模型，并给辅助损失分配一个 0.2 的权重。如果要为不同的输出指定不同的 <code>loss_weights</code> 或 <code>loss</code>，可以使用列表或字典。 在这里，我们给 <code>loss</code> 参数传递单个损失函数，这个损失将用于所有的输出。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">'rmsprop'</span>, loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">              loss_weights=[<span class="number">1.</span>, <span class="number">0.2</span>])</span><br></pre></td></tr></tbody></table></figure>
<p>我们可以通过传递输入数组和目标数组的列表来训练模型：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.fit([headline_data, additional_data], [labels, labels],</span><br><span class="line">          epochs=<span class="number">50</span>, batch_size=<span class="number">32</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>由于输入和输出均被命名了（在定义时传递了一个 <code>name</code> 参数），我们也可以通过以下方式编译模型：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">              loss={<span class="string">'main_output'</span>: <span class="string">'binary_crossentropy'</span>, <span class="string">'aux_output'</span>: <span class="string">'binary_crossentropy'</span>},</span><br><span class="line">              loss_weights={<span class="string">'main_output'</span>: <span class="number">1.</span>, <span class="string">'aux_output'</span>: <span class="number">0.2</span>})</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后使用以下方式训练：</span></span><br><span class="line">model.fit({<span class="string">'main_input'</span>: headline_data, <span class="string">'aux_input'</span>: additional_data},</span><br><span class="line">          {<span class="string">'main_output'</span>: labels, <span class="string">'aux_output'</span>: labels},</span><br><span class="line">          epochs=<span class="number">50</span>, batch_size=<span class="number">32</span>)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="共享网络层"><a href="#共享网络层" class="headerlink" title="共享网络层"></a>共享网络层</h3><p>函数式 API 的另一个用途是使用共享网络层的模型。我们来看看共享层。</p>
<p>来考虑推特推文数据集。我们想要建立一个模型来分辨两条推文是否来自同一个人（例如，通过推文的相似性来对用户进行比较）。</p>
<p>实现这个目标的一种方法是建立一个模型，将两条推文编码成两个向量，连接向量，然后添加逻辑回归层；这将输出两条推文来自同一作者的概率。模型将接收一对对正负表示的推特数据。</p>
<p>由于这个问题是对称的，编码第一条推文的机制应该被完全重用来编码第二条推文（权重及其他全部）。这里我们使用一个共享的 LSTM 层来编码推文。</p>
<p>让我们使用函数式 API 来构建它。首先我们将一条推特转换为一个尺寸为 <code>(280, 256)</code> 的矩阵，即每条推特 280 字符，每个字符为 256 维的 one-hot 编码向量 （取 256 个常用字符）。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, LSTM, Dense</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line">tweet_a = Input(shape=(<span class="number">280</span>, <span class="number">256</span>))</span><br><span class="line">tweet_b = Input(shape=(<span class="number">280</span>, <span class="number">256</span>))</span><br></pre></td></tr></tbody></table></figure>
<p>要在不同的输入上共享同一个层，只需实例化该层一次，然后根据需要传入你想要的输入即可：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这一层可以输入一个矩阵，并返回一个 64 维的向量</span></span><br><span class="line">shared_lstm = LSTM(<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 当我们重用相同的图层实例多次，图层的权重也会被重用 (它其实就是同一层)</span></span><br><span class="line">encoded_a = shared_lstm(tweet_a)</span><br><span class="line">encoded_b = shared_lstm(tweet_b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后再连接两个向量：</span></span><br><span class="line">merged_vector = keras.layers.concatenate([encoded_a, encoded_b], axis=<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 再在上面添加一个逻辑回归层</span></span><br><span class="line">predictions = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)(merged_vector)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个连接推特输入和预测的可训练的模型</span></span><br><span class="line">model = Model(inputs=[tweet_a, tweet_b], outputs=predictions)</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">              loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.fit([data_a, data_b], labels, epochs=<span class="number">10</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>让我们暂停一会，看看如何读取共享层的输出或输出尺寸。</p>
<h3 id="层「节点」的概念"><a href="#层「节点」的概念" class="headerlink" title="层「节点」的概念"></a>层「节点」的概念</h3><p>每当你在某个输入上调用一个层时，都将创建一个新的张量（层的输出），并且为该层添加一个「节点」，将输入张量连接到输出张量。当多次调用同一个图层时，该图层将拥有多个节点索引 (0, 1, 2…)。</p>
<p>在之前版本的 Keras 中，可以通过 <code>layer.get_output()</code> 来获得层实例的输出张量，或者通过 <code>layer.output_shape</code> 来获取其输出形状。现在你依然可以这么做（除了 <code>get_output()</code> 已经被 <code>output</code> 属性替代）。但是如果一个层与多个输入连接呢？</p>
<p>只要一个层仅仅连接到一个输入，就不会有困惑，<code>.output</code> 会返回层的唯一输出：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = Input(shape=(<span class="number">280</span>, <span class="number">256</span>))</span><br><span class="line"></span><br><span class="line">lstm = LSTM(<span class="number">32</span>)</span><br><span class="line">encoded_a = lstm(a)</span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> lstm.output == encoded_a</span><br></pre></td></tr></tbody></table></figure>
<p>但是如果该层有多个输入，那就会出现问题：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">a = Input(shape=(<span class="number">280</span>, <span class="number">256</span>))</span><br><span class="line">b = Input(shape=(<span class="number">280</span>, <span class="number">256</span>))</span><br><span class="line"></span><br><span class="line">lstm = LSTM(<span class="number">32</span>)</span><br><span class="line">encoded_a = lstm(a)</span><br><span class="line">encoded_b = lstm(b)</span><br><span class="line"></span><br><span class="line">lstm.output</span><br><span class="line">&gt;&gt; AttributeError: Layer lstm_1 has multiple inbound nodes,</span><br><span class="line">hence the notion of <span class="string">"layer output"</span> <span class="keyword">is</span> ill-defined.</span><br><span class="line">Use `get_output_at(node_index)` instead.</span><br></pre></td></tr></tbody></table></figure>
<p>好吧，通过下面的方法可以解决：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assert</span> lstm.get_output_at(<span class="number">0</span>) == encoded_a</span><br><span class="line"><span class="keyword">assert</span> lstm.get_output_at(<span class="number">1</span>) == encoded_b</span><br></pre></td></tr></tbody></table></figure>
<p>够简单，对吧？</p>
<p><code>input_shape</code> 和 <code>output_shape</code> 这两个属性也是如此：只要该层只有一个节点，或者只要所有节点具有相同的输入/输出尺寸，那么「层输出/输入尺寸」的概念就被很好地定义，并且将由 <code>layer.output_shape</code> / <code>layer.input_shape</code> 返回。但是比如说，如果将一个 <code>Conv2D</code> 层先应用于尺寸为 <code>(32，32，3)</code> 的输入，再应用于尺寸为 <code>(64, 64, 3)</code> 的输入，那么这个层就会有多个输入/输出尺寸，你将不得不通过指定它们所属节点的索引来获取它们：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">a = Input(shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>))</span><br><span class="line">b = Input(shape=(<span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">conv = Conv2D(<span class="number">16</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'same'</span>)</span><br><span class="line">conved_a = conv(a)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 到目前为止只有一个输入，以下可行：</span></span><br><span class="line"><span class="keyword">assert</span> conv.input_shape == (<span class="literal">None</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">conved_b = conv(b)</span><br><span class="line"><span class="comment"># 现在 `.input_shape` 属性不可行，但是这样可以：</span></span><br><span class="line"><span class="keyword">assert</span> conv.get_input_shape_at(<span class="number">0</span>) == (<span class="literal">None</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>)</span><br><span class="line"><span class="keyword">assert</span> conv.get_input_shape_at(<span class="number">1</span>) == (<span class="literal">None</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="Inception-模型"><a href="#Inception-模型" class="headerlink" title="Inception 模型"></a>Inception 模型</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, MaxPooling2D, Input</span><br><span class="line"></span><br><span class="line">input_img = Input(shape=(<span class="number">256</span>, <span class="number">256</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">tower_1 = Conv2D(<span class="number">64</span>, (<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>)(input_img)</span><br><span class="line">tower_1 = Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>)(tower_1)</span><br><span class="line"></span><br><span class="line">tower_2 = Conv2D(<span class="number">64</span>, (<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>)(input_img)</span><br><span class="line">tower_2 = Conv2D(<span class="number">64</span>, (<span class="number">5</span>, <span class="number">5</span>), padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>)(tower_2)</span><br><span class="line"></span><br><span class="line">tower_3 = MaxPooling2D((<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'same'</span>)(input_img)</span><br><span class="line">tower_3 = Conv2D(<span class="number">64</span>, (<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>)(tower_3)</span><br><span class="line"></span><br><span class="line">output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=<span class="number">1</span>)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="卷积层上的残差连接"><a href="#卷积层上的残差连接" class="headerlink" title="卷积层上的残差连接"></a>卷积层上的残差连接</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, Input</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入张量为 3 通道 256x256 图像</span></span><br><span class="line">x = Input(shape=(<span class="number">256</span>, <span class="number">256</span>, <span class="number">3</span>))</span><br><span class="line"><span class="comment"># 3 输出通道（与输入通道相同）的 3x3 卷积核</span></span><br><span class="line">y = Conv2D(<span class="number">3</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'same'</span>)(x)</span><br><span class="line"><span class="comment"># 返回 x + y</span></span><br><span class="line">z = keras.layers.add([x, y])</span><br></pre></td></tr></tbody></table></figure>
<h3 id="共享视觉模型"><a href="#共享视觉模型" class="headerlink" title="共享视觉模型"></a>共享视觉模型</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, MaxPooling2D, Input, Dense, Flatten</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 首先，定义视觉模型</span></span><br><span class="line">digit_input = Input(shape=(<span class="number">27</span>, <span class="number">27</span>, <span class="number">1</span>))</span><br><span class="line">x = Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>))(digit_input)</span><br><span class="line">x = Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>))(x)</span><br><span class="line">x = MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>))(x)</span><br><span class="line">out = Flatten()(x)</span><br><span class="line"></span><br><span class="line">vision_model = Model(digit_input, out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后，定义区分数字的模型</span></span><br><span class="line">digit_a = Input(shape=(<span class="number">27</span>, <span class="number">27</span>, <span class="number">1</span>))</span><br><span class="line">digit_b = Input(shape=(<span class="number">27</span>, <span class="number">27</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 视觉模型将被共享，包括权重和其他所有</span></span><br><span class="line">out_a = vision_model(digit_a)</span><br><span class="line">out_b = vision_model(digit_b)</span><br><span class="line"></span><br><span class="line">concatenated = keras.layers.concatenate([out_a, out_b])</span><br><span class="line">out = Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)(concatenated)</span><br><span class="line"></span><br><span class="line">classification_model = Model([digit_a, digit_b], out)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="视觉问答模型"><a href="#视觉问答模型" class="headerlink" title="视觉问答模型"></a>视觉问答模型</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, MaxPooling2D, Flatten</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, LSTM, Embedding, Dense</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model, Sequential</span><br><span class="line"></span><br><span class="line"><span class="comment"># 首先，让我们用 Sequential 来定义一个视觉模型。</span></span><br><span class="line"><span class="comment"># 这个模型会把一张图像编码为向量。</span></span><br><span class="line">vision_model = Sequential()</span><br><span class="line">vision_model.add(Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>, input_shape=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>)))</span><br><span class="line">vision_model.add(Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">vision_model.add(MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">vision_model.add(Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>))</span><br><span class="line">vision_model.add(Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">vision_model.add(MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">vision_model.add(Conv2D(<span class="number">256</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>))</span><br><span class="line">vision_model.add(Conv2D(<span class="number">256</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">vision_model.add(Conv2D(<span class="number">256</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">vision_model.add(MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">vision_model.add(Flatten())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 现在让我们用视觉模型来得到一个输出张量：</span></span><br><span class="line">image_input = Input(shape=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))</span><br><span class="line">encoded_image = vision_model(image_input)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来，定义一个语言模型来将问题编码成一个向量。</span></span><br><span class="line"><span class="comment"># 每个问题最长 100 个词，词的索引从 1 到 9999.</span></span><br><span class="line">question_input = Input(shape=(<span class="number">100</span>,), dtype=<span class="string">'int32'</span>)</span><br><span class="line">embedded_question = Embedding(input_dim=<span class="number">10000</span>, output_dim=<span class="number">256</span>, input_length=<span class="number">100</span>)(question_input)</span><br><span class="line">encoded_question = LSTM(<span class="number">256</span>)(embedded_question)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 连接问题向量和图像向量：</span></span><br><span class="line">merged = keras.layers.concatenate([encoded_question, encoded_image])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后在上面训练一个 1000 词的逻辑回归模型：</span></span><br><span class="line">output = Dense(<span class="number">1000</span>, activation=<span class="string">'softmax'</span>)(merged)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最终模型：</span></span><br><span class="line">vqa_model = Model(inputs=[image_input, question_input], outputs=output)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下一步就是在真实数据上训练模型。</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="视频问答模型"><a href="#视频问答模型" class="headerlink" title="视频问答模型"></a>视频问答模型</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> TimeDistributed</span><br><span class="line"></span><br><span class="line">video_input = Input(shape=(<span class="number">100</span>, <span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))</span><br><span class="line"><span class="comment"># 这是基于之前定义的视觉模型（权重被重用）构建的视频编码</span></span><br><span class="line">encoded_frame_sequence = TimeDistributed(vision_model)(video_input)  <span class="comment"># 输出为向量的序列</span></span><br><span class="line">encoded_video = LSTM(<span class="number">256</span>)(encoded_frame_sequence)  <span class="comment"># 输出为一个向量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这是问题编码器的模型级表示，重复使用与之前相同的权重：</span></span><br><span class="line">question_encoder = Model(inputs=question_input, outputs=encoded_question)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 让我们用它来编码这个问题：</span></span><br><span class="line">video_question_input = Input(shape=(<span class="number">100</span>,), dtype=<span class="string">'int32'</span>)</span><br><span class="line">encoded_video_question = question_encoder(video_question_input)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这就是我们的视频问答模式：</span></span><br><span class="line">merged = keras.layers.concatenate([encoded_video, encoded_video_question])</span><br><span class="line">output = Dense(<span class="number">1000</span>, activation=<span class="string">'softmax'</span>)(merged)</span><br><span class="line">video_qa_model = Model(inputs=[video_input, video_question_input], outputs=output)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="3-Sequential模型API"><a href="#3-Sequential模型API" class="headerlink" title="3. Sequential模型API"></a>3. Sequential模型API</h2><h3 id="Sequential模型方法"><a href="#Sequential模型方法" class="headerlink" title="Sequential模型方法"></a>Sequential模型方法</h3><h4 id="compile"><a href="#compile" class="headerlink" title="compile"></a>compile</h4><p>用于配置训练模型</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">compile</span>(optimizer,loss=<span class="literal">None</span>,metrics=<span class="literal">None</span>,loss_weights=<span class="literal">None</span>,sample_weight=<span class="literal">None</span>,weighted_metrics=<span class="literal">None</span>,traget_tensors=<span class="literal">None</span>)</span><br></pre></td></tr></tbody></table></figure>
<h5 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h5><ul>
<li><strong>optimizer</strong>: 字符串（优化器名）或者优化器对象。</li>
<li><strong>loss</strong>: 字符串（目标函数名）或目标函数。</li>
<li><strong>metrics</strong>: 在训练和测试期间的模型评估标准。</li>
<li><strong>loss_weights</strong>: 指定标量系数（Python浮点数）的可选列表或字典，用于加权不同模型输出的损失贡献。</li>
<li><strong>sample_weight_mode</strong>: 如果你需要执行按时间步采样权重（2D 权重），请将其设置为 <code>temporal</code>。</li>
<li><strong>weighted_metrics</strong>: 在训练和测试期间，由 sample_weight 或 class_weight 评估和加权的度量标准列表。</li>
<li><strong>target_tensors</strong>: 默认情况下，Keras 将为模型的目标创建一个占位符，在训练过程中将使用目标数据。</li>
</ul>
<h5 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h5><ul>
<li><strong>ValueError</strong>: 如果 <code>optimizer</code>, <code>loss</code>, <code>metrics</code> 或 <code>sample_weight_mode</code> 这些参数不合法。</li>
</ul>
<h4 id="fit"><a href="#fit" class="headerlink" title="fit"></a>fit</h4><p>以固定数量的轮次训练模型</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fit(x=<span class="literal">None</span>, y=<span class="literal">None</span>, batch_size=<span class="literal">None</span>, epochs=<span class="number">1</span>, verbose=<span class="number">1</span>, callbacks=<span class="literal">None</span>, validation_split=<span class="number">0.0</span>, validation_data=<span class="literal">None</span>, shuffle=<span class="literal">True</span>, class_weight=<span class="literal">None</span>, sample_weight=<span class="literal">None</span>, initial_epoch=<span class="number">0</span>, steps_per_epoch=<span class="literal">None</span>, validation_steps=<span class="literal">None</span>)</span><br></pre></td></tr></tbody></table></figure>
<h5 id="参数-1"><a href="#参数-1" class="headerlink" title="参数"></a>参数</h5><ul>
<li><strong>x</strong>: 训练数据的 Numpy 数组。 如果模型中的输入层被命名，你也可以传递一个字典，将输入层名称映射到 Numpy 数组。 如果从本地框架张量馈送（例如 TensorFlow 数据张量）数据，x 可以是 <code>None</code>（默认）。</li>
<li><strong>y</strong>: 目标（标签）数据的 Numpy 数组。 如果模型中的输出层被命名，你也可以传递一个字典，将输出层名称映射到 Numpy 数组。 如果从本地框架张量馈送（例如 TensorFlow 数据张量）数据，y 可以是 <code>None</code>（默认）。</li>
<li><strong>batch_size</strong>: 整数或 <code>None</code>。每次提度更新的样本数。如果未指定，默认为 32.</li>
<li><strong>epochs</strong>: 整数。训练模型迭代轮次。一个轮次是在整个 <code>x</code> 或 <code>y</code> 上的一轮迭代。请注意，与 <code>initial_epoch</code> 一起，<code>epochs</code> 被理解为 「最终轮次」。模型并不是训练了 <code>epochs</code> 轮，而是到第 <code>epochs</code> 轮停止训练。</li>
<li><strong>verbose</strong>: 0, 1 或 2。日志显示模式。 0 = 安静模式, 1 = 进度条, 2 = 每轮一行。</li>
<li><strong>callbacks</strong>: 一系列的 <code>keras.callbacks.Callback</code> 实例。一系列可以在训练时使用的回调函数。</li>
<li><strong>validation_split</strong>: 在 0 和 1 之间浮动。用作验证集的训练数据的比例。模型将分出一部分不会被训练的验证数据，并将在每一轮结束时评估这些验证数据的误差和任何其他模型指标。验证数据是混洗之前 <code>x</code> 和<code>y</code> 数据的最后一部分样本中。</li>
<li><strong>validation_data</strong>: 元组 <code>(x_val，y_val)</code> 或元组 <code>(x_val，y_val，val_sample_weights)</code>，用来评估损失，以及在每轮结束时的任何模型度量指标。模型将不会在这个数据上进行训练。这个参数会覆盖 <code>validation_split</code>。</li>
<li><strong>shuffle</strong>: 布尔值（是否在每轮迭代之前混洗数据）或者 字符串 (<code>batch</code>)。<code>batch</code> 是处理 HDF5 数据限制的特殊选项，它对一个 batch 内部的数据进行混洗。当 <code>steps_per_epoch</code> 非 <code>None</code> 时，这个参数无效。</li>
<li><strong>class_weight</strong>: 可选的字典，用来映射类索引（整数）到权重（浮点）值，用于加权损失函数（仅在训练期间）。这可能有助于告诉模型 「更多关注」来自代表性不足的类的样本。</li>
<li><strong>sample_weight</strong>: 训练样本的可选 Numpy 权重数组，用于对损失函数进行加权（仅在训练期间）。您可以传递与输入样本长度相同的平坦（1D）Numpy 数组（权重和样本之间的 1：1 映射），或者在时序数据的情况下，可以传递尺寸为 <code>(samples, sequence_length)</code> 的 2D 数组，以对每个样本的每个时间步施加不同的权重。在这种情况下，你应该确保在 <code>compile()</code> 中指定 <code>sample_weight_mode="temporal"</code>。</li>
<li><strong>initial_epoch</strong>: 开始训练的轮次（有助于恢复之前的训练）。</li>
<li><strong>steps_per_epoch</strong>: 在声明一个轮次完成并开始下一个轮次之前的总步数（样品批次）。使用 TensorFlow 数据张量等输入张量进行训练时，默认值 <code>None</code> 等于数据集中样本的数量除以 batch 的大小，如果无法确定，则为 1。</li>
<li><strong>validation_steps</strong>: 只有在指定了 <code>steps_per_epoch</code>时才有用。停止前要验证的总步数（批次样本）。</li>
</ul>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a class="post-meta__tags" href="/tags/Keras/">Keras</a></div><div class="post_share"><div class="social-share" data-image="/images/cover1.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/08/07/python-shen-du-xue-xi/"><img class="prev-cover" src="/images/cover2.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Python深度学习</div></div></a></div><div class="next-post pull-right"><a href="/2020/08/01/2020-8/"><img class="next-cover" src="/images/cover4.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">2020-8</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2020/08/07/python-shen-du-xue-xi/" title="Python深度学习"><img class="cover" src="/images/cover2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-08-07</div><div class="title">Python深度学习</div></div></a></div><div><a href="/2020/06/10/tong-ji-xue-xi-fang-fa/" title="统计学习方法"><img class="cover" src="/images/cover5.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-10</div><div class="title">统计学习方法</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/images/avataaars.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">月落</div><div class="author-info__description">学习记录，日常随笔</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">63</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">43</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Wanfengyueluo/"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Wanfengyueluo" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:wanfengwind@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">但行好事，莫问前程~</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Keras-Sequentical%E9%A1%BA%E5%BA%8F%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">1. Keras Sequentical顺序模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%87%E5%AE%9A%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E7%9A%84%E5%B0%BA%E5%AF%B8"><span class="toc-number">1.1.</span> <span class="toc-text">指定输入数据的尺寸</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%BC%96%E8%AF%91"><span class="toc-number">1.2.</span> <span class="toc-text">模型编译</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">1.3.</span> <span class="toc-text">模型训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B7%E4%BE%8B"><span class="toc-number">1.4.</span> <span class="toc-text">样例</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E5%99%A8%EF%BC%88MLP%EF%BC%89%E7%9A%84softmax%E5%A4%9A%E5%88%86%E7%B1%BB%EF%BC%9A"><span class="toc-number">1.4.1.</span> <span class="toc-text">基于多层感知器（MLP）的softmax多分类：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E5%99%A8%E7%9A%84%E4%BA%8C%E5%88%86%E7%B1%BB%EF%BC%9A"><span class="toc-number">1.4.2.</span> <span class="toc-text">基于多层感知器的二分类：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B1%BB%E4%BC%BC-VGG-%E7%9A%84%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9A"><span class="toc-number">1.4.3.</span> <span class="toc-text">类似 VGG 的卷积神经网络：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Keras-%E5%87%BD%E6%95%B0%E5%BC%8FAPI"><span class="toc-number">2.</span> <span class="toc-text">2.     Keras 函数式API</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BE%8B%E4%B8%80%EF%BC%9A%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%BD%91%E7%BB%9C"><span class="toc-number">2.1.</span> <span class="toc-text">例一：全连接网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%80%E6%9C%89%E7%9A%84%E6%A8%A1%E5%9E%8B%E9%83%BD%E5%8F%AF%E8%B0%83%E7%94%A8%EF%BC%8C%E5%B0%B1%E5%83%8F%E7%BD%91%E7%BB%9C%E5%B1%82%E4%B8%80%E6%A0%B7"><span class="toc-number">2.2.</span> <span class="toc-text">所有的模型都可调用，就像网络层一样</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E8%BE%93%E5%85%A5%E5%A4%9A%E8%BE%93%E5%87%BA%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.3.</span> <span class="toc-text">多输入多输出模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B1%E4%BA%AB%E7%BD%91%E7%BB%9C%E5%B1%82"><span class="toc-number">2.4.</span> <span class="toc-text">共享网络层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B1%82%E3%80%8C%E8%8A%82%E7%82%B9%E3%80%8D%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="toc-number">2.5.</span> <span class="toc-text">层「节点」的概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Inception-%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.6.</span> <span class="toc-text">Inception 模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82%E4%B8%8A%E7%9A%84%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5"><span class="toc-number">2.7.</span> <span class="toc-text">卷积层上的残差连接</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B1%E4%BA%AB%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.8.</span> <span class="toc-text">共享视觉模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%86%E8%A7%89%E9%97%AE%E7%AD%94%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.9.</span> <span class="toc-text">视觉问答模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%86%E9%A2%91%E9%97%AE%E7%AD%94%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.10.</span> <span class="toc-text">视频问答模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Sequential%E6%A8%A1%E5%9E%8BAPI"><span class="toc-number">3.</span> <span class="toc-text">3. Sequential模型API</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Sequential%E6%A8%A1%E5%9E%8B%E6%96%B9%E6%B3%95"><span class="toc-number">3.1.</span> <span class="toc-text">Sequential模型方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#compile"><span class="toc-number">3.1.1.</span> <span class="toc-text">compile</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8F%82%E6%95%B0"><span class="toc-number">3.1.1.1.</span> <span class="toc-text">参数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%BC%82%E5%B8%B8"><span class="toc-number">3.1.1.2.</span> <span class="toc-text">异常</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#fit"><span class="toc-number">3.1.2.</span> <span class="toc-text">fit</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8F%82%E6%95%B0-1"><span class="toc-number">3.1.2.1.</span> <span class="toc-text">参数</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/04/06/jian-zhi-offer-xi-lie/" title="剑指Offer系列"><img src="/images/cover5.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="剑指Offer系列"/></a><div class="content"><a class="title" href="/2022/04/06/jian-zhi-offer-xi-lie/" title="剑指Offer系列">剑指Offer系列</a><time datetime="2022-04-06T11:10:42.000Z" title="发表于 2022-04-06 19:10:42">2022-04-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/12/06/ji-yu-da-shu-ju-de-tu-shu-tui-jian-xi-tong-xi-tong-wu-chi-xian-tui-jian/" title="基于大数据的图书推荐系统系统（五）——离线推荐"><img src="https://cdn.jsdelivr.net/gh/Wanfengyueluo/images/image-20211206214617246.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于大数据的图书推荐系统系统（五）——离线推荐"/></a><div class="content"><a class="title" href="/2021/12/06/ji-yu-da-shu-ju-de-tu-shu-tui-jian-xi-tong-xi-tong-wu-chi-xian-tui-jian/" title="基于大数据的图书推荐系统系统（五）——离线推荐">基于大数据的图书推荐系统系统（五）——离线推荐</a><time datetime="2021-12-06T13:21:55.000Z" title="发表于 2021-12-06 21:21:55">2021-12-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/12/06/ji-yu-da-shu-ju-de-tu-shu-tui-jian-xi-tong-xi-tong-si-shu-ju-tong-ji/" title="基于大数据的图书推荐系统系统（四）——数据统计"><img src="https://cdn.jsdelivr.net/gh/Wanfengyueluo/images/image-20211206214617246.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于大数据的图书推荐系统系统（四）——数据统计"/></a><div class="content"><a class="title" href="/2021/12/06/ji-yu-da-shu-ju-de-tu-shu-tui-jian-xi-tong-xi-tong-si-shu-ju-tong-ji/" title="基于大数据的图书推荐系统系统（四）——数据统计">基于大数据的图书推荐系统系统（四）——数据统计</a><time datetime="2021-12-06T13:20:26.000Z" title="发表于 2021-12-06 21:20:26">2021-12-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/12/06/ji-yu-da-shu-ju-de-tu-shu-tui-jian-xi-tong-xi-tong-san-shu-ju-jia-zai-yu-cun-chu/" title="基于大数据的图书推荐系统系统（三）——数据加载与存储"><img src="https://cdn.jsdelivr.net/gh/Wanfengyueluo/images/image-20211206214617246.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于大数据的图书推荐系统系统（三）——数据加载与存储"/></a><div class="content"><a class="title" href="/2021/12/06/ji-yu-da-shu-ju-de-tu-shu-tui-jian-xi-tong-xi-tong-san-shu-ju-jia-zai-yu-cun-chu/" title="基于大数据的图书推荐系统系统（三）——数据加载与存储">基于大数据的图书推荐系统系统（三）——数据加载与存储</a><time datetime="2021-12-06T13:18:41.000Z" title="发表于 2021-12-06 21:18:41">2021-12-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/12/06/ji-yu-da-shu-ju-de-tu-shu-tui-jian-xi-tong-xi-tong-er-ruan-jian-an-zhuang/" title="基于大数据的图书推荐系统系统（二）——软件安装"><img src="https://cdn.jsdelivr.net/gh/Wanfengyueluo/images/image-20211206214617246.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于大数据的图书推荐系统系统（二）——软件安装"/></a><div class="content"><a class="title" href="/2021/12/06/ji-yu-da-shu-ju-de-tu-shu-tui-jian-xi-tong-xi-tong-er-ruan-jian-an-zhuang/" title="基于大数据的图书推荐系统系统（二）——软件安装">基于大数据的图书推荐系统系统（二）——软件安装</a><time datetime="2021-12-06T13:14:21.000Z" title="发表于 2021-12-06 21:14:21">2021-12-06</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/images/cover1.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2022 By 月落</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><a target="_blank" rel="noopener" href="http://www.beian.miit.gov.cn/"><img class="icp-icon" src="/images/icp.png"><span>备案号：浙ICP备20029443号</span></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>