---
title: 大数据开发环境搭建
date: 2020-06-01 19:39:31
description: 大数据开发环境搭建
categories: Hadoop
tags: 
	- 大数据
	- Hadoop
---

# 大数据开发环境搭建笔记

## 1.虚拟机基本设置

## 2.JDK安装配置

- 下载并解压jdk

- 配置JDK环境变量

  ```shell
  #JAVA_HOME
  export JAVA_HOME=(jdk安装目录)
  export PATH=$PATH:$JAVA_HOME/bin
  ```

<!-- more -->

## 3.Hadoop安装配置

- 下载并解压Hadoop

- 配置Hadoop环境变量

  ```shell
  export HADOOP_HOME=(hadoop安装目录)
  export PATH=$PATH:$HADOOP_HOME/bin
  export PATH=$PATH:$HADOOP_HOME/sbin
  ```

- 配置core-site.xml

  ```xml
  <configuration>
      <!-- 指定HDFS中NameNode的地址 -->
      <property>
          <name>fs.defaultFS</name>
          <value>hdfs://hadoop100:9000</value>
      </property>
      <!-- 指定Hadoop运行时产生文件的存储目录 -->
      <property>
  		<name>hadoop.tmp.dir</name>
  		<value>/app/hadoop-3.2.0/tmp</value>
  	</property>
  </configuration>
  ```

- 配置hdfs-site.xml

  ```xml
  <configuration>
      <!-- 指定HDFS副本的数量 -->
      <property>
          <name>dfs.replication</name>
          <value>1</value>
      </property>
  	<!-- 指定Hadoop辅助节点主机配置 -->
  	<property>
  		<name>dfs.namenode.secondary.http-address</name>
  		<value>hadoop100:50090</value>
  	</property>
  </configuration>
  ```

- 配置hadoop-env.sh

  ```sh
  export JAVA_HOME={$JAVA_HOME}
  ```

> 解决WARN util.NativeCodeLoader: *Unable* *to* *load* *native-hadoop* *library* *for* *your* *platform*... *using* *builtin-java* classes where applicable的方法
>
> 1. 下载 http://dl.bintray.com/sequenceiq/sequenceiq-bin/hadoop-native-64.tar
> 2. 解压到$HADOOP_HOME/lib/native和$HADOOP_HOME/lib下
> 3. `export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native`
> 4. `export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib"`
> 5. `source /etc/profile`生效

- 配置yarn-env.sh

  ```sh
  export JAVA_HOME=/usr/java/jdk1.8.0_231-amd64
  export JAVA_HOME=/opt/jdk1.8.0_251
  ```

- 配置yarn-site.xml

  ```xml
  <configuration>
  	<!-- Reducer获取数据的方式 -->
  	<property>
  		<name>yarn.nodemanager.aux-services</name>
  		<value>mapreduce_shuffle</value>
  	</property>
  
  	<!-- 指定YARN的ResourceManager的地址 -->
  	<property>
  		<name>yarn.resourcemanager.hostname</name>
  		<value>hadoop103</value>
  	</property>
      <property>
  		<name>yarn.nodemanager.env-whitelist</name>
  		<value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CL
  ASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
  	</property>
  </configuration>
  ```

- 配置mapred-site.xml

  ```xml
  <configuration>
      <!-- 指定MR运行在Yarn上 -->
    <property>
  		<name>mapreduce.framework.name</name>
  		<value>yarn</value>
      </property>
  </configuration>
  ```
  
- 配置mapred-env.sh

  ```sh
  export JAVA_HOME=/usr/java/jdk1.8.0_231-amd64
  ```

- 群起集群，配置workers

  ```shell
  # 添加DataNode的主机
  hadoop102
  hadoop103
  hadoop104
  ```

- 配置启动脚本

  - start-dfs.sh

    ```sh
    HDFS_DATANODE_USER=root
    HDFS_DATANODE_SECURE_USER=hdfs
    HDFS_NAMENODE_USER=root
    HDFS_SECONDARYNAMENODE_USER=root
    ```

  - stop-dfs.sh

    ```sh
    HDFS_DATANODE_USER=root
    HDFS_DATANODE_SECURE_USER=hdfs
    HDFS_NAMENODE_USER=root
    HDFS_SECONDARYNAMENODE_USER=root
    ```

  - start-yarn.sh

    ```sh
    YARN_RESOURCEMANAGER_USER=root
    HADOOP_SECURE_DN_USER=yarn
    YARN_NODEMANAGER_USER=root
    ```

  - stop-yarn.sh

    ```sh
    YARN_RESOURCEMANAGER_USER=root
    HADOOP_SECURE_DN_USER=yarn
    YARN_NODEMANAGER_USER=root
    ```

- 启动（注意分发安装包）

  - 第一次需要格式化，注意格式化之前要停止上次启动的NameNode和DataNode，删除data和log数据
  
  - 格式化`bin/hdfs namenode -format`
  
    > 多次格式化可能会出现datanode无法正常启动的问题
  
  - 启动hdfs`sbin/start-dfs.sh`
  
  - 启动yarn`sbin/start-yarn.sh`，启动Yarn需要在ResourceManager所在的节点上启动

